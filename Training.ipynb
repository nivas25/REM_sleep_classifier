{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPDg8QQdyarKltVc2NFahAN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["print(\"Installing necessary libraries...\")\n","import sys\n","!{sys.executable} -m pip install -q pandas scikit-learn xgboost imbalanced-learn\n","print(\"Libraries installed successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GxmXS6VLRCMp","executionInfo":{"status":"ok","timestamp":1753445360841,"user_tz":-330,"elapsed":2570,"user":{"displayName":"Reddy Sai Nivas","userId":"08366611169748950347"}},"outputId":"4e327ffc-fcb9-4c0e-819b-9c14be1e50a1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing necessary libraries...\n","Libraries installed successfully.\n"]}]},{"cell_type":"code","source":["print(\"Connecting to Google Drive...\")\n","\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    print(\"Google Drive successfully mounted.\")\n","except Exception as e:\n","    print(f\"Failed to connect to Google Drive: {e}\")\n","    raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHPfGJVMJysX","executionInfo":{"status":"ok","timestamp":1753445972540,"user_tz":-330,"elapsed":33806,"user":{"displayName":"Reddy Sai Nivas","userId":"08366611169748950347"}},"outputId":"122be231-02ed-4d83-9b4c-f2a21cdc2c0d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Connecting to Google Drive...\n","Mounted at /content/drive\n","Google Drive successfully mounted.\n"]}]},{"cell_type":"code","source":["TRAINING_CSV_PATH = '/content/drive/MyDrive/ANPHY/master_training_dataset_imputed.csv'\n","TEST_DATA_FOLDER = '/content/drive/MyDrive/ANPHY/test_subjects/'"],"metadata":{"id":"kq5mAXjtRSmS","executionInfo":{"status":"ok","timestamp":1753445972542,"user_tz":-330,"elapsed":14,"user":{"displayName":"Reddy Sai Nivas","userId":"08366611169748950347"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import glob\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","\n","# --- Core ML Libraries ---\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.neural_network import MLPClassifier\n","\n","# --- Models ---\n","from sklearn.ensemble import RandomForestClassifier\n","import xgboost as xgb\n","import lightgbm as lgb\n","from sklearn.linear_model import LogisticRegression\n","\n","# --- Imbalance Handling ---\n","from imblearn.over_sampling import ADASYN\n","\n","# Suppress warnings for a cleaner output\n","warnings.filterwarnings('ignore')\n","\n","# =============================================================================\n","# --- Configuration ---\n","# =============================================================================\n","TRAINING_CSV_PATH = '/content/drive/MyDrive/ANPHY/master_training_dataset_imputed.csv'\n","TEST_DATA_FOLDER = '/content/drive/MyDrive/ANPHY/test_subjects/'\n","TARGET_COLUMN = 'sleep_stage'\n","ROLLING_WINDOW_SIZE = 5 # 5 epochs = 2.5 minutes\n","\n","# =============================================================================\n","# --- Helper Functions ---\n","# =============================================================================\n","def create_trend_features(df, window_size):\n","    \"\"\"\n","    Creates advanced trend features (moving averages and std deviations)\n","    for key signals, grouped by subject.\n","    \"\"\"\n","    print(\"Creating advanced trend features...\")\n","    # Define the key features we want to create trends for\n","    key_features = ['emg_rms', 'eog_std', 'eog_kurtosis'] + [col for col in df.columns if 'hjorth' in col]\n","\n","    all_subjects_data = []\n","    for subject, subject_df in df.groupby('subject_id'):\n","        subject_df = subject_df.reset_index(drop=True)\n","        # Calculate rolling mean and std for each key feature\n","        for col in key_features:\n","            if col in subject_df.columns:\n","                subject_df[f'{col}_rolling_mean_{window_size}'] = subject_df[col].rolling(window=window_size, min_periods=1).mean()\n","                subject_df[f'{col}_rolling_std_{window_size}'] = subject_df[col].rolling(window=window_size, min_periods=1).std()\n","\n","        # Fill any remaining NaNs at the beginning\n","        subject_df.fillna(method='bfill', inplace=True)\n","        subject_df.fillna(method='ffill', inplace=True)\n","        all_subjects_data.append(subject_df)\n","\n","    return pd.concat(all_subjects_data, ignore_index=True)\n","\n","# =============================================================================\n","# --- Main Execution ---\n","# =============================================================================\n","print(\"--- Starting State-of-the-Art Stacking Ensemble Pipeline ---\")\n","\n","# --- 1. Load, Engineer, and Preprocess Training Data ---\n","print(\"\\n--- [Phase 1] Preparing Training Data ---\")\n","train_df_raw = pd.read_csv(TRAINING_CSV_PATH)\n","# **NEW:** Add the advanced trend features\n","train_df = create_trend_features(train_df_raw, ROLLING_WINDOW_SIZE)\n","\n","feature_cols = [c for c in train_df.columns if c not in ['subject_id', 'sleep_stage', 'is_rem']]\n","X_train = train_df[feature_cols]\n","y_train_text = train_df[TARGET_COLUMN]\n","\n","le = LabelEncoder()\n","y_train = le.fit_transform(y_train_text)\n","class_names = le.classes_\n","print(f\"Labels encoded. Class order: {list(class_names)}\")\n","\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","\n","print(\"Handling class imbalance with ADASYN...\")\n","adasyn = ADASYN(random_state=42)\n","X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train_scaled, y_train)\n","print(f\"Resampled training data shape: {X_train_resampled.shape}\")\n","\n","# --- 2. Build and Train the Stacking Ensemble Model ---\n","print(\"\\n--- [Phase 2] Building and Training the Ensemble of Experts ---\")\n","\n","# Define the \"Expert\" base models with good, tuned parameters\n","estimators = [\n","    ('xgb', xgb.XGBClassifier(n_estimators=200, max_depth=7, learning_rate=0.2, subsample=0.7, colsample_bytree=0.7, random_state=42, n_jobs=-1)),\n","    ('lgbm', lgb.LGBMClassifier(random_state=42, n_jobs=-1)),\n","    ('rf', RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1)),\n","    ('mlp', MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300, random_state=42))\n","]\n","\n","# Define the \"Manager\" meta-model\n","# This model's job is to learn from the predictions of the experts.\n","meta_model = LogisticRegression(max_iter=1000)\n","\n","# Create the Stacking Classifier\n","stacking_model = StackingClassifier(\n","    estimators=estimators,\n","    final_estimator=meta_model,\n","    cv=3, # Use cross-validation to generate predictions for the meta-model\n","    n_jobs=-1\n",")\n","\n","print(\"Training the full Stacking Ensemble... (this may take some time)\")\n","stacking_model.fit(X_train_resampled, y_train_resampled)\n","print(\"Ensemble model trained successfully.\")\n","\n","# --- 3. Final Evaluation on Each Unseen Test Subject ---\n","print(\"\\n--- [Phase 3] Evaluating Tuned Model on Unseen Test Subjects ---\")\n","test_files = glob.glob(os.path.join(TEST_DATA_FOLDER, '*.csv'))\n","all_results = []\n","\n","for test_file in test_files:\n","    subject_id = os.path.basename(test_file).split('_')[0]\n","    print(\"\\n\" + \"=\"*60)\n","    print(f\"--- Testing on Subject: {subject_id} ---\")\n","\n","    # Load and prepare this single subject's data\n","    raw_test_df = pd.read_csv(test_file)\n","    test_df = create_trend_features(raw_test_df, ROLLING_WINDOW_SIZE)\n","\n","    # Align columns and separate X/y\n","    X_test = test_df[feature_cols]\n","    y_test_text = test_df[TARGET_COLUMN]\n","\n","    # Preprocess\n","    y_test = le.transform(y_test_text)\n","    X_test_scaled = scaler.transform(X_test)\n","\n","    # Evaluate the best model on this subject\n","    y_pred = stacking_model.predict(X_test_scaled)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    rem_f1 = f1_score(y_test, y_pred, labels=[list(class_names).index('REM')], average='macro', zero_division=0)\n","\n","    print(f\"Performance for {subject_id}: Accuracy={accuracy:.3f}, REM F1={rem_f1:.3f}\")\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_test, y_pred, target_names=class_names, zero_division=0))\n","\n","    all_results.append({'Subject': subject_id, 'Accuracy': accuracy, 'REM_F1_Score': rem_f1})\n","\n","# --- 4. Grand Finale: Averaged Performance Summary ---\n","print(\"\\n\" + \"=\"*60)\n","print(\"--- FINAL RESULT: AVERAGED PERFORMANCE ACROSS ALL TEST SUBJECTS ---\")\n","results_df = pd.DataFrame(all_results)\n","avg_accuracy = results_df['Accuracy'].mean()\n","std_accuracy = results_df['Accuracy'].std()\n","avg_rem_f1 = results_df['REM_F1_Score'].mean()\n","std_rem_f1 = results_df['REM_F1_Score'].std()\n","print(f\"Average Overall Accuracy: {avg_accuracy:.4f} ± {std_accuracy:.4f}\")\n","print(f\"Average REM F1-Score:   {avg_rem_f1:.4f} ± {std_rem_f1:.4f}\")\n","print(\"=\"*60)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ii_7nHYCZ5FN","executionInfo":{"status":"ok","timestamp":1753446809247,"user_tz":-330,"elapsed":836711,"user":{"displayName":"Reddy Sai Nivas","userId":"08366611169748950347"}},"outputId":"a127eff6-ad55-449b-e0a4-0a675a50ca0d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting State-of-the-Art Stacking Ensemble Pipeline ---\n","\n","--- [Phase 1] Preparing Training Data ---\n","Creating advanced trend features...\n","Labels encoded. Class order: ['N1', 'N2', 'N3', 'REM', 'Wake']\n","Handling class imbalance with ADASYN...\n","Resampled training data shape: (41112, 153)\n","\n","--- [Phase 2] Building and Training the Ensemble of Experts ---\n","Training the full Stacking Ensemble... (this may take some time)\n","Ensemble model trained successfully.\n","\n","--- [Phase 3] Evaluating Tuned Model on Unseen Test Subjects ---\n","\n","============================================================\n","--- Testing on Subject: EPCTL04 ---\n","Creating advanced trend features...\n","Performance for EPCTL04: Accuracy=0.852, REM F1=0.792\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","          N1       0.55      0.44      0.49        95\n","          N2       0.84      0.88      0.86       214\n","          N3       0.99      0.90      0.94       124\n","         REM       0.79      0.80      0.79        74\n","        Wake       0.91      0.97      0.94       255\n","\n","    accuracy                           0.85       762\n","   macro avg       0.81      0.80      0.80       762\n","weighted avg       0.85      0.85      0.85       762\n","\n","\n","============================================================\n","--- Testing on Subject: EPCTL01 ---\n","Creating advanced trend features...\n","Performance for EPCTL01: Accuracy=0.772, REM F1=0.800\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","          N1       0.46      0.22      0.29        74\n","          N2       0.72      1.00      0.83       471\n","          N3       1.00      0.51      0.68       185\n","         REM       0.93      0.70      0.80       176\n","        Wake       0.94      0.65      0.77        51\n","\n","    accuracy                           0.77       957\n","   macro avg       0.81      0.62      0.67       957\n","weighted avg       0.80      0.77      0.75       957\n","\n","\n","============================================================\n","--- Testing on Subject: EPCTL08 ---\n","Creating advanced trend features...\n","Performance for EPCTL08: Accuracy=0.746, REM F1=0.625\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","          N1       0.38      0.10      0.15        83\n","          N2       0.72      0.83      0.77       334\n","          N3       0.80      0.83      0.82       165\n","         REM       0.53      0.76      0.62        79\n","        Wake       0.92      0.79      0.85       212\n","\n","    accuracy                           0.75       873\n","   macro avg       0.67      0.66      0.64       873\n","weighted avg       0.73      0.75      0.73       873\n","\n","\n","============================================================\n","--- FINAL RESULT: AVERAGED PERFORMANCE ACROSS ALL TEST SUBJECTS ---\n","Average Overall Accuracy: 0.7899 ± 0.0552\n","Average REM F1-Score:   0.7390 ± 0.0988\n","============================================================\n"]}]},{"cell_type":"code","source":["import joblib\n","import os\n","\n","# =============================================================================\n","# --- Configuration ---\n","# =============================================================================\n","# Define the folder where you want to save your final, trained model components.\n","MODEL_OUTPUT_FOLDER = '/content/drive/MyDrive/ANPHY/final_model/'\n","os.makedirs(MODEL_OUTPUT_FOLDER, exist_ok=True) # Create folder if it doesn't exist\n","\n","# Define the filenames for each component of our pipeline.\n","MODEL_FILE_PATH = os.path.join(MODEL_OUTPUT_FOLDER, 'sleep_staging_model.joblib')\n","SCALER_FILE_PATH = os.path.join(MODEL_OUTPUT_FOLDER, 'feature_scaler.joblib')\n","LABEL_ENCODER_PATH = os.path.join(MODEL_OUTPUT_FOLDER, 'label_encoder.joblib')\n","\n","# =============================================================================\n","# --- Main Execution ---\n","# =============================================================================\n","print(\"\\n\" + \"=\"*60)\n","print(\"--- SAVING THE FINAL TRAINED MODEL AND PIPELINE COMPONENTS ---\")\n","print(\"=\"*60)\n","\n","# --- 1. Save the Stacking Ensemble Model ---\n","# This is our \"Ensemble of Experts\" model that we trained.\n","print(f\"Saving the trained Stacking Ensemble model to: {MODEL_FILE_PATH}\")\n","# The 'stacking_model' variable should exist from the previous cell where we trained it.\n","joblib.dump(stacking_model, MODEL_FILE_PATH)\n","print(\"Model saved successfully.\")\n","\n","# --- 2. Save the Feature Scaler ---\n","# This is CRITICAL. To make predictions on a new subject, you must scale\n","# their features in the exact same way as the training data.\n","print(f\"\\nSaving the feature scaler to: {SCALER_FILE_PATH}\")\n","# The 'scaler' variable was fitted on our training data in the previous cell.\n","joblib.dump(scaler, SCALER_FILE_PATH)\n","print(\"Scaler saved successfully.\")\n","\n","# --- 3. Save the Label Encoder ---\n","# This is also CRITICAL. It holds the mapping between the numerical predictions\n","# (e.g., 4) and the human-readable sleep stage labels (e.g., 'REM').\n","print(f\"\\nSaving the label encoder to: {LABEL_ENCODER_PATH}\")\n","# The 'le' variable was fitted on our training labels in the previous cell.\n","joblib.dump(le, LABEL_ENCODER_PATH)\n","print(\"Label encoder saved successfully.\")\n","\n","print(\"\\n--- Saving Complete ---\")\n","print(\"You can now load these three files in a new script to make predictions on new subjects without retraining.\")\n","\n"],"metadata":{"id":"v23XIgkpqHrq","executionInfo":{"status":"ok","timestamp":1753448220847,"user_tz":-330,"elapsed":1201,"user":{"displayName":"Reddy Sai Nivas","userId":"08366611169748950347"}},"outputId":"694a003b-4538-4d86-c467-33c5a52bb00a","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","--- SAVING THE FINAL TRAINED MODEL AND PIPELINE COMPONENTS ---\n","============================================================\n","Saving the trained Stacking Ensemble model to: /content/drive/MyDrive/ANPHY/final_model/sleep_staging_model.joblib\n","Model saved successfully.\n","\n","Saving the feature scaler to: /content/drive/MyDrive/ANPHY/final_model/feature_scaler.joblib\n","Scaler saved successfully.\n","\n","Saving the label encoder to: /content/drive/MyDrive/ANPHY/final_model/label_encoder.joblib\n","Label encoder saved successfully.\n","\n","--- Saving Complete ---\n","You can now load these three files in a new script to make predictions on new subjects without retraining.\n"]}]}]}